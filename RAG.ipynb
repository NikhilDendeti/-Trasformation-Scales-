{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcGFqVnSThU0bJaTAY8ouL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikhilDendeti/-Trasformation-Scales-/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myJE7D0nbiKc",
        "outputId": "650e1694-4b17-48cb-e24f-22046d0d76e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.1)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.1)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.26.4)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.1)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (2.27.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers qdrant-client\n",
        "!pip install pymupdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import fitz\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Step 1: Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Initialize the path to your PDF document\n",
        "pdf_path = '/content/drive/My Drive/Insurance Industry _ Report.pdf'\n",
        "\n",
        "# Step 3: Read the PDF document using PyMuPDF (fitz)\n",
        "doc = fitz.open(pdf_path)\n",
        "\n",
        "# Step 4: Function to extract text from PDF and split it into chunks of 500 words\n",
        "def split_into_chunks_by_words(text, words_per_chunk=500):\n",
        "    \"\"\"\n",
        "    Split the document text into chunks of a specified number of words.\n",
        "    \"\"\"\n",
        "    words = text.split()  # Split text into words\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for word in words:\n",
        "        current_chunk.append(word)\n",
        "        if len(current_chunk) == words_per_chunk:\n",
        "            chunks.append(\" \".join(current_chunk))  # Join the words to form a chunk\n",
        "            current_chunk = []  # Reset for the next chunk\n",
        "\n",
        "    # Add any remaining words as the last chunk\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Step 5: Extract text from each page and split it into chunks\n",
        "doc_content = \"\"\n",
        "for page_num in range(len(doc)):\n",
        "    page = doc.load_page(page_num)\n",
        "    doc_content += page.get_text()\n",
        "\n",
        "# Step 6: Split the extracted document content into smaller chunks (500 words per chunk)\n",
        "chunks = split_into_chunks_by_words(doc_content, words_per_chunk=500)\n",
        "\n",
        "# Step 7: Initialize Sentence Transformer for document embeddings\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Step 8: Generate embeddings for each chunk\n",
        "embeddings = model.encode(chunks)\n",
        "\n",
        "# Step 9: Set up Qdrant client (using your provided Qdrant instance URL and API key)\n",
        "qdrant_url = 'https://8db3766a-65c1-409f-aaa9-79d79321e863.europe-west3-0.gcp.cloud.qdrant.io:6333'  # Provided Qdrant URL\n",
        "api_key = 'xyB4yWC3aXxMfv8VET4cLZdpwMziZ0EM2j3BMQ6gUy--t6G7jVmx8w'  # Provided API Key\n",
        "\n",
        "# Initialize Qdrant client\n",
        "client = QdrantClient(url=qdrant_url, api_key=api_key)\n",
        "\n",
        "# Step 10: Create a collection in Qdrant to store the embeddings if it doesn't exist\n",
        "collection_name = \"google_doc_embeddings\"\n",
        "if not client.collection_exists(collection_name):\n",
        "    client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config=VectorParams(size=embeddings.shape[1], distance=Distance.COSINE)\n",
        "    )\n",
        "\n",
        "# Step 11: Upload the document chunk embeddings to Qdrant\n",
        "points = [\n",
        "    {\"id\": idx + 1, \"vector\": embedding.tolist(), \"payload\": {\"text\": chunk}}\n",
        "    for idx, (chunk, embedding) in enumerate(zip(chunks, embeddings))\n",
        "]\n",
        "client.upsert(collection_name=collection_name, points=points)\n",
        "\n",
        "# Step 12: Perform a search to find the most suitable chunk for a query\n",
        "query = \"What is insurence company do?\"\n",
        "query_embedding = model.encode([query])[0]\n",
        "\n",
        "# Perform the search in Qdrant\n",
        "search_results = client.search(\n",
        "    collection_name=collection_name,\n",
        "    query_vector=query_embedding.tolist(),\n",
        "    limit=3  # Adjust based on how many results you want\n",
        ")\n",
        "\n",
        "# Step 13: Display the search results in a structured format\n",
        "print(\"\\nSearch Results:\")\n",
        "for result in search_results:\n",
        "    # Show part of the document chunk (first 500 characters) in a more structured format\n",
        "    document_chunk = result.payload['text']\n",
        "\n",
        "    # Ensure it is split into lines or paragraphs for better readability\n",
        "    paragraphs = document_chunk.split(\"\\n\")\n",
        "\n",
        "    # Display the result with improved formatting\n",
        "    print(f\"Score: {result.score:.4f}\")\n",
        "    print(\"Document Chunk: \")\n",
        "\n",
        "    # Show the first few paragraphs (or lines) to give a preview\n",
        "    preview = \"\\n\".join(paragraphs[:5])  # Show first 5 paragraphs (adjust as needed)\n",
        "    print(preview)\n",
        "\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "SgpUxW31bm5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d22c0c5-edc4-4115-b85b-50d56b09d690"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Search Results:\n",
            "Score: 0.5281\n",
            "Document Chunk: \n",
            "○​ Insurers must manage diverse regulatory frameworks and \n",
            "provide consistent global coverage for multinational \n",
            "clients.\n",
            "Strategic Recommendations\n",
            "1. Embrace Technology for Operational Efficiency\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Score: 0.5059\n",
            "Document Chunk: \n",
            "○​ Innovation: Telematics-based auto insurance adjusting \n",
            "premiums according to driving behavior.\n",
            "○​ Impact: Rewards safe driving, increasing customer loyalty.\n",
            "5.​ InsureMO’s PaaS Solutions:​\n",
            "○​ Innovation: A platform-as-a-service enabling insurers to \n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Score: 0.5011\n",
            "Document Chunk: \n",
            "and Retaliation Employee retaliation after reporting fraud Resolved through settlement Commission Dispute Termination following unpaid commission inquiry Favorable settlement for employee Minority Shareholders' Fraud Discovery of embezzlement in corporate governance Settlement secured protecting interests Implications for Regulatory Practices The complexities of global compliance necessitate robust regulatory practices in the insurance industry: 1.​ Comprehensive Compliance Programs:​ ○​ Insurers must develop frameworks encompassing all relevant regulations. Employee training ensures awareness and adherence to compliance responsibilities. 2.​ Regular Audits and Assessments:​ ○​ Conducting periodic audits identifies non-compliance risks, enabling corrective actions before legal issues arise. Reviews should cover internal controls and risk management systems. 3.​ Enhanced Reporting Mechanisms:​ ○​ Clear reporting channels encourage transparency and accountability, allowing employees to report fraud or misconduct without fear of retaliation. 4.​ Legal Expertise Integration:​ ○​ Engaging legal professionals ensures insurers remain informed about evolving regulations and develop strategies to mitigate potential legal challenges. XXI. Innovation and Product Development in the Insurance Industry The insurance industry is undergoing a significant transformation driven by innovation and the development of new products tailored to evolving consumer needs. This report explores trends in insurance product offerings, highlights case studies of innovative products, and discusses their implications for the industry. Trends in Insurance Product Offerings 1.​ Microinsurance:​ ○​ Low-cost coverage designed for specific risks, often targeting underserved populations. ○​ Example: Microinsurance for online purchases protects consumers against fraud, shipping damage, or dissatisfaction. 2.​ On-Demand Insurance:​ ○​ Flexible coverage activated as needed, catering to consumers who want short-term or event-specific protection. ○​ Example: Temporary insurance for electronic devices during travel or events. 3.​ Behavior-Based Insurance:​ ○​ Leverages telematics and IoT data to adjust premiums based on individual behavior, encouraging safer practices. ○​ Example: Auto insurance premiums are adjusted based on driving habits tracked via telematics devices. 4.​ Embedded Insurance:​ ○​ Integrates coverage directly into the purchase of products or services, simplifying access for consumers. ○​ Example: Tesla embeds auto insurance with driving habit analysis into its vehicle purchase process. 5.​ Personalized Health Insurance:​ ○​ Adjusts premiums based on individual health metrics, promoting healthier lifestyles. ○​ Example: Wearable-based health insurance plans offer discounts for demonstrated healthy behaviors. Table: Current Trends in Insurance Product Offerings Trend Description Example Microinsurance Affordable, specific coverage Online purchase protection On-Demand Insurance Flexible, need-based coverage Temporary electronic device insurance Behavior-Based Insurance Dynamic premiums based on behavior Driving habit-based auto insurance Embedded Insurance Built-in coverage with product/service purchases Tesla’s integrated auto insurance Personalized Health Insurance Plans tailored to individual health metrics Health insurance linked to wearables Case Studies of Innovative Insurance Products 1.​ Lemonade:​ ○​ Innovation: AI-powered claims processing that settles claims within seconds. ○​ Impact: Enhanced transparency, reduced operational costs, and faster customer service. 2.​ Zego:​ ○​ Innovation: Flexible motor insurance for gig economy workers with pay-as-you-go options. ○​ Impact: Customizable coverage addressing dynamic customer needs. 3.​ John Hancock’s Vitality Program:​ ○​ Innovation: Life insurance linked to fitness tracking devices, offering rewards and premium discounts based on health metrics. ○​ Impact: Encourages healthier lifestyles and improves customer engagement. 4.​\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YY_YRx28zh9M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}